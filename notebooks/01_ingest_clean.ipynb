{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d12cacf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 01_ingest_clean.ipynb\n",
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "# ------------------------------\n",
    "# Paths\n",
    "# ------------------------------\n",
    "BASE_DIR = \"../\"\n",
    "RAW_DIR = os.path.join(BASE_DIR, \"data/raw\")\n",
    "PROCESSED_DIR = os.path.join(BASE_DIR, \"data/processed\")\n",
    "os.makedirs(PROCESSED_DIR, exist_ok=True)\n",
    "\n",
    "# ------------------------------\n",
    "# Load datasets\n",
    "# ------------------------------\n",
    "try:\n",
    "    df_ev = pd.read_csv(os.path.join(RAW_DIR, \"ev_registrations.csv\"))\n",
    "    print(\"EV Registrations loaded\")\n",
    "except FileNotFoundError:\n",
    "    print(\"ev_registrations.csv not found in data/raw\")\n",
    "\n",
    "try:\n",
    "    df_pop = pd.read_csv(os.path.join(RAW_DIR, \"population.csv\"))\n",
    "    print(\"Population data loaded\")\n",
    "except FileNotFoundError:\n",
    "    print(\"population.csv not found in data/raw\")\n",
    "\n",
    "# ------------------------------\n",
    "# Quick inspection\n",
    "# ------------------------------\n",
    "print(\"EV data sample:\")\n",
    "display(df_ev.head())\n",
    "\n",
    "print(\"Population data sample:\")\n",
    "display(df_pop.head())\n",
    "\n",
    "# ------------------------------\n",
    "# Basic cleaning function\n",
    "# ------------------------------\n",
    "def clean_data(df):\n",
    "    df = df.drop_duplicates()\n",
    "    df.columns = df.columns.str.strip()\n",
    "    # Fill numeric missing values\n",
    "    num_cols = df.select_dtypes(include=\"number\").columns\n",
    "    df[num_cols] = df[num_cols].fillna(0)\n",
    "    # Fill categorical missing values\n",
    "    cat_cols = df.select_dtypes(include=\"object\").columns\n",
    "    df[cat_cols] = df[cat_cols].fillna(\"Unknown\")\n",
    "    return df\n",
    "\n",
    "df_ev_clean = clean_data(df_ev)\n",
    "df_pop_clean = clean_data(df_pop)\n",
    "\n",
    "# ------------------------------\n",
    "# Save cleaned datasets\n",
    "# ------------------------------\n",
    "df_ev_clean.to_csv(os.path.join(PROCESSED_DIR, \"ev_registrations_clean.csv\"), index=False)\n",
    "df_pop_clean.to_csv(os.path.join(PROCESSED_DIR, \"population_clean.csv\"), index=False)\n",
    "\n",
    "print(\"Processed files saved to data/processed/\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "876f288e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pandas in c:\\users\\abhay\\ev-charging-demand-analysis\\.venv\\lib\\site-packages (2.3.2)\n",
      "Requirement already satisfied: numpy>=1.26.0 in c:\\users\\abhay\\ev-charging-demand-analysis\\.venv\\lib\\site-packages (from pandas) (2.3.3)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\users\\abhay\\ev-charging-demand-analysis\\.venv\\lib\\site-packages (from pandas) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\abhay\\ev-charging-demand-analysis\\.venv\\lib\\site-packages (from pandas) (2025.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in c:\\users\\abhay\\ev-charging-demand-analysis\\.venv\\lib\\site-packages (from pandas) (2025.2)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\abhay\\ev-charging-demand-analysis\\.venv\\lib\\site-packages (from python-dateutil>=2.8.2->pandas) (1.17.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "ev_registrations.csv not found in data/raw\n",
      "population.csv not found in data/raw\n",
      "EV data not loaded.\n",
      "Population data not loaded.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 24.3.1 -> 25.2\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'NoneType' object has no attribute 'drop_duplicates'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mAttributeError\u001b[39m                            Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[3]\u001b[39m\u001b[32m, line 62\u001b[39m\n\u001b[32m     59\u001b[39m     df[cat_cols] = df[cat_cols].fillna(\u001b[33m\"\u001b[39m\u001b[33mUnknown\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m     60\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m df\n\u001b[32m---> \u001b[39m\u001b[32m62\u001b[39m df_ev_clean = \u001b[43mclean_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdf_ev\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     63\u001b[39m df_pop_clean = clean_data(df_pop)\n\u001b[32m     65\u001b[39m \u001b[38;5;66;03m# ------------------------------\u001b[39;00m\n\u001b[32m     66\u001b[39m \u001b[38;5;66;03m# Save cleaned datasets\u001b[39;00m\n\u001b[32m     67\u001b[39m \u001b[38;5;66;03m# ------------------------------\u001b[39;00m\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[3]\u001b[39m\u001b[32m, line 52\u001b[39m, in \u001b[36mclean_data\u001b[39m\u001b[34m(df)\u001b[39m\n\u001b[32m     51\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mclean_data\u001b[39m(df):\n\u001b[32m---> \u001b[39m\u001b[32m52\u001b[39m     df = \u001b[43mdf\u001b[49m\u001b[43m.\u001b[49m\u001b[43mdrop_duplicates\u001b[49m()\n\u001b[32m     53\u001b[39m     df.columns = df.columns.str.strip()\n\u001b[32m     54\u001b[39m     \u001b[38;5;66;03m# Fill numeric missing values\u001b[39;00m\n",
      "\u001b[31mAttributeError\u001b[39m: 'NoneType' object has no attribute 'drop_duplicates'"
     ]
    }
   ],
   "source": [
    "%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "add91293",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚ùå File final_dataset.csv not found in c:\\Users\\Abhay\\EV-Charging-Demand-Analysis\\notebooks\\data\\raw\n",
      "‚ùå File ev-charging-stations-india.csv not found in c:\\Users\\Abhay\\EV-Charging-Demand-Analysis\\notebooks\\data\\raw\n",
      "‚ùå File EV Maker by Place.csv not found in c:\\Users\\Abhay\\EV-Charging-Demand-Analysis\\notebooks\\data\\raw\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "# ------------------------------\n",
    "# 1. Define folder paths\n",
    "# ------------------------------\n",
    "try:\n",
    "    BASE_DIR = os.path.dirname(os.path.abspath(__file__))  # if .py\n",
    "except NameError:\n",
    "    BASE_DIR = os.getcwd()  # if Jupyter\n",
    "\n",
    "RAW_DIR = os.path.join(BASE_DIR, \"data\", \"raw\")\n",
    "PROCESSED_DIR = os.path.join(BASE_DIR, \"data\", \"processed\")\n",
    "os.makedirs(PROCESSED_DIR, exist_ok=True)\n",
    "\n",
    "# ------------------------------\n",
    "# 2. Generic cleaning function\n",
    "# ------------------------------\n",
    "def clean_data(df):\n",
    "    \"\"\"Basic cleaning: drop duplicates, trim col names, fill NaN\"\"\"\n",
    "    df = df.drop_duplicates()\n",
    "    df.columns = df.columns.str.strip().str.lower().str.replace(\" \", \"_\")\n",
    "    \n",
    "    # Fill missing numeric with 0\n",
    "    num_cols = df.select_dtypes(include=\"number\").columns\n",
    "    df[num_cols] = df[num_cols].fillna(0)\n",
    "    \n",
    "    # Fill missing categorical with 'Unknown'\n",
    "    cat_cols = df.select_dtypes(include=\"object\").columns\n",
    "    df[cat_cols] = df[cat_cols].fillna(\"Unknown\")\n",
    "    \n",
    "    return df\n",
    "\n",
    "# ------------------------------\n",
    "# 3. Load datasets\n",
    "# ------------------------------\n",
    "datasets = {\n",
    "    \"final_dataset.csv\": None,\n",
    "    \"ev-charging-stations-india.csv\": None,\n",
    "    \"EV Maker by Place.csv\": None\n",
    "}\n",
    "\n",
    "for fname in datasets.keys():\n",
    "    path = os.path.join(RAW_DIR, fname)\n",
    "    if os.path.exists(path):\n",
    "        df = pd.read_csv(path, encoding=\"utf-8\", low_memory=False)\n",
    "        print(f\"Loaded {fname} ‚Üí Shape: {df.shape}\")\n",
    "        datasets[fname] = df\n",
    "    else:\n",
    "        print(f\"‚ùå File {fname} not found in {RAW_DIR}\")\n",
    "\n",
    "# ------------------------------\n",
    "# 4. Clean & Save\n",
    "# ------------------------------\n",
    "for fname, df in datasets.items():\n",
    "    if df is not None:\n",
    "        df_clean = clean_data(df)\n",
    "        out_name = fname.replace(\".csv\", \"_clean.csv\").lower().replace(\" \", \"_\")\n",
    "        out_path = os.path.join(PROCESSED_DIR, out_name)\n",
    "        df_clean.to_csv(out_path, index=False)\n",
    "        print(f\"‚úÖ Cleaned {fname} ‚Üí Saved as {out_name}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b6802fcf",
   "metadata": {},
   "outputs": [],
   "source": [
    "BASE_DIR = os.getcwd()\n",
    "RAW_DIR = os.path.join(BASE_DIR, \"data\", \"raw\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "cdd6c67a",
   "metadata": {},
   "outputs": [],
   "source": [
    "BASE_DIR = os.path.abspath(os.path.join(os.getcwd(), \"..\"))  # go one level up\n",
    "RAW_DIR = os.path.join(BASE_DIR, \"data\", \"raw\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d53a2e49",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Base directory: c:\\Users\\Abhay\\EV-Charging-Demand-Analysis\n",
      "Raw data directory: c:\\Users\\Abhay\\EV-Charging-Demand-Analysis\\data\\raw\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "# ------------------------------\n",
    "# Correct project base path\n",
    "# ------------------------------\n",
    "try:\n",
    "    BASE_DIR = os.path.dirname(os.path.abspath(__file__))  # if .py script\n",
    "except NameError:\n",
    "    BASE_DIR = os.path.abspath(os.path.join(os.getcwd(), \"..\"))  # if Jupyter\n",
    "\n",
    "RAW_DIR = os.path.join(BASE_DIR, \"data\", \"raw\")\n",
    "PROCESSED_DIR = os.path.join(BASE_DIR, \"data\", \"processed\")\n",
    "os.makedirs(PROCESSED_DIR, exist_ok=True)\n",
    "\n",
    "print(\"Base directory:\", BASE_DIR)\n",
    "print(\"Raw data directory:\", RAW_DIR)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9e54b9ff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Loaded final_dataset.csv ‚Üí Shape: (32, 13)\n",
      "‚úÖ Loaded ev-charging-stations-india.csv ‚Üí Shape: (1547, 7)\n",
      "‚úÖ Loaded EV Maker by Place.csv ‚Üí Shape: (62, 3)\n",
      "‚ùå File not found: ev-cat_01-24.csv\n",
      "‚úÖ Loaded operationalPC.csv ‚Üí Shape: (34, 2)\n",
      "‚ùå File not found: Vehicle cladd-All.csv\n",
      "üíæ Cleaned final_dataset.csv ‚Üí Saved as final_dataset_clean.csv\n",
      "   unnamed:_0                  state_name  two_wheeler  three_wheeler  \\\n",
      "0           0  Andaman and Nicobar Island            1           30.0   \n",
      "1           1           Arunachal Pradesh           14            0.0   \n",
      "2           2                       Assam          721        47041.0   \n",
      "3           3                       Bihar         5003        59079.0   \n",
      "4           4                  Chandigarh          298         1410.0   \n",
      "\n",
      "   four_wheeler  goods_vehicles  public_service_vehicle  \\\n",
      "0            81             0.0                    40.0   \n",
      "1             5             0.0                     0.0   \n",
      "2           161             7.0                    15.0   \n",
      "3           114            11.0                    26.0   \n",
      "4           182             0.0                    40.0   \n",
      "\n",
      "   special_category_vehicles  ambulance/hearses  \\\n",
      "0                        0.0                0.0   \n",
      "1                        0.0                0.0   \n",
      "2                        0.0                0.0   \n",
      "3                        0.0                0.0   \n",
      "4                        0.0                0.0   \n",
      "\n",
      "   construction_equipment_vehicle  other  grand_total  total-charging-stations  \n",
      "0                             0.0    7.0          159                      0.0  \n",
      "1                             0.0    1.0           20                      0.0  \n",
      "2                             0.0    2.0        47947                     10.0  \n",
      "3                             0.0    8.0        64241                      9.0  \n",
      "4                             0.0    1.0         1931                      2.0   \n",
      "\n",
      "üíæ Cleaned ev-charging-stations-india.csv ‚Üí Saved as ev-charging-stations-india_clean.csv\n",
      "                                                name          state      city  \\\n",
      "0                 Neelkanth Star DC Charging Station        Haryana  Gurugram   \n",
      "1                       Galleria DC Charging Station        Haryana  Gurugram   \n",
      "2  Highway Xpress (Jaipur-Delhi) DC charging station      Rajasthan    Behror   \n",
      "3                  Food Carnival DC Charging Station  Uttar Pradesh  Khatauli   \n",
      "4                  Food Carnival AC Charging Station  Uttar Pradesh  Khatauli   \n",
      "\n",
      "                                             address lattitude  longitude  \\\n",
      "0  Neelkanth Star Karnal, NH 44, Gharunda, Kutail...   29.6019    76.9803   \n",
      "1  DLF Phase IV, Sector 28, Gurugram, Haryana 122022   28.4673    77.0818   \n",
      "2  Jaipur to Delhi Road, Behror Midway, Behror, R...   27.8751    76.2760   \n",
      "3  Fun and Food Carnival, NH 58, Khatauli Bypass,...   29.3105    77.7218   \n",
      "4  NH 58, Khatauli Bypass, Bhainsi, Uttar Pradesh...   29.3105    77.7218   \n",
      "\n",
      "   type  \n",
      "0  12.0  \n",
      "1  12.0  \n",
      "2  12.0  \n",
      "3  12.0  \n",
      "4  12.0   \n",
      "\n",
      "üíæ Cleaned EV Maker by Place.csv ‚Üí Saved as ev_maker_by_place_clean.csv\n",
      "            ev_maker        place        state\n",
      "0        Tata Motors         Pune  Maharashtra\n",
      "1  Mahindra Electric    Bengaluru    Karnataka\n",
      "2       Ather Energy    Bengaluru    Karnataka\n",
      "3      Hero Electric    New Delhi        Delhi\n",
      "4       Ola Electric  Krishnagiri   Tamil Nadu \n",
      "\n",
      "üíæ Cleaned operationalPC.csv ‚Üí Saved as operationalpc_clean.csv\n",
      "               state  no._of_operational_pcs\n",
      "0  Andaman & Nicobar                       3\n",
      "1     Andhra Pradesh                     327\n",
      "2  Arunachal Pradesh                       9\n",
      "3              Assam                      86\n",
      "4              Bihar                     124 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "# ------------------------------\n",
    "# 3. List of datasets to load\n",
    "# ------------------------------\n",
    "file_list = [\n",
    "    \"final_dataset.csv\",\n",
    "    \"ev-charging-stations-india.csv\",\n",
    "    \"EV Maker by Place.csv\",\n",
    "    \"ev-cat_01-24.csv\",\n",
    "    \"operationalPC.csv\",\n",
    "    \"Vehicle cladd-All.csv\"\n",
    "]\n",
    "\n",
    "datasets = {}\n",
    "\n",
    "# ------------------------------\n",
    "# 4. Load datasets\n",
    "# ------------------------------\n",
    "for fname in file_list:\n",
    "    path = os.path.join(RAW_DIR, fname)\n",
    "    if os.path.exists(path):\n",
    "        try:\n",
    "            df = pd.read_csv(path, encoding=\"utf-8\", low_memory=False)\n",
    "        except UnicodeDecodeError:\n",
    "            df = pd.read_csv(path, encoding=\"latin1\", low_memory=False)  # fallback\n",
    "        print(f\"‚úÖ Loaded {fname} ‚Üí Shape: {df.shape}\")\n",
    "        datasets[fname] = df\n",
    "    else:\n",
    "        print(f\"‚ùå File not found: {fname}\")\n",
    "\n",
    "# ------------------------------\n",
    "# 5. Clean & Save\n",
    "# ------------------------------\n",
    "for fname, df in datasets.items():\n",
    "    df_clean = clean_data(df)\n",
    "    out_name = fname.replace(\".csv\", \"_clean.csv\").lower().replace(\" \", \"_\")\n",
    "    out_path = os.path.join(PROCESSED_DIR, out_name)\n",
    "    df_clean.to_csv(out_path, index=False)\n",
    "    print(f\"üíæ Cleaned {fname} ‚Üí Saved as {out_name}\")\n",
    "    print(df_clean.head(), \"\\n\")  # preview\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "805955a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_data(df):\n",
    "    df = df.copy()  # ‚úÖ make sure we‚Äôre working on a full copy\n",
    "    df = df.drop_duplicates()\n",
    "    df.columns = df.columns.str.strip().str.lower().str.replace(\" \", \"_\")\n",
    "\n",
    "    # Fill numeric missing values\n",
    "    num_cols = df.select_dtypes(include=[\"float64\", \"int64\"]).columns\n",
    "    df.loc[:, num_cols] = df[num_cols].fillna(0)\n",
    "\n",
    "    # Fill categorical missing values\n",
    "    cat_cols = df.select_dtypes(include=[\"object\"]).columns\n",
    "    df.loc[:, cat_cols] = df[cat_cols].fillna(\"Unknown\")\n",
    "\n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1aa3aca",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv (3.13.1)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
